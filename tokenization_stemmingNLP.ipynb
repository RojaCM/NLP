{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RojaCM/NLP/blob/main/tokenization_stemmingNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IW-NmHGZQNZF"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qWjQn0K-QNZK"
      },
      "outputs": [],
      "source": [
        "filename ='FP.txt'\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "zyR0G3T0SU3c",
        "outputId": "cb51db8b-e205-464e-e84b-e8a08a95f4d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6AKn0HW5QNZL",
        "outputId": "070d2b43-8c2c-465b-8987-27c6381a3b23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿This is financial Report of 2019-2020\n",
            "\n",
            "\n",
            "\n",
            "The share of large borrowers in Indian banks’ total loan portfolios stood at 53% as on March 2019\n",
            "\n",
            "The gross non-performing assets (NPAs) as a percentage of total loans stood at 9.3% as on March 2019\n",
            "\n",
            "Mumbai: Indian banks continue to see an improvement in asset quality with bad loans as a percentage of total loans expected to fall to 9% by March 2020, according to the Financial Stability Report released by the Reserve Bank of India (RBI) on Thursday.\n"
          ]
        }
      ],
      "source": [
        "# split into sentences\n",
        "from nltk import sent_tokenize\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kJzO4-46QNZN",
        "outputId": "3d468a7a-6d18-441e-f6cf-851023952257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeffThis', 'is', 'financial', 'Report', 'of', '2019-2020', 'The', 'share', 'of', 'large', 'borrowers', 'in', 'Indian', 'banks', '’', 'total', 'loan', 'portfolios', 'stood', 'at', '53', '%', 'as', 'on', 'March', '2019', 'The', 'gross', 'non-performing', 'assets', '(', 'NPAs', ')', 'as', 'a', 'percentage', 'of', 'total', 'loans', 'stood', 'at', '9.3', '%', 'as', 'on', 'March', '2019', 'Mumbai', ':', 'Indian', 'banks', 'continue', 'to', 'see', 'an', 'improvement', 'in', 'asset', 'quality', 'with', 'bad', 'loans', 'as', 'a', 'percentage', 'of', 'total', 'loans', 'expected', 'to', 'fall', 'to', '9', '%', 'by', 'March', '2020', ',', 'according', 'to', 'the', 'Financial', 'Stability', 'Report', 'released', 'by', 'the', 'Reserve', 'Bank', 'of', 'India', '(', 'RBI', ')', 'on', 'Thursday', '.', 'The', 'gross', 'non-performing']\n"
          ]
        }
      ],
      "source": [
        "from nltk import word_tokenize\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yp2bc_UIQNZO"
      },
      "outputs": [],
      "source": [
        "words = [word for word in tokens if word.isalpha()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0xun9QqQNZO",
        "outputId": "6cb3cf04-7fb8-4d79-f0d2-dd68a0dbe8e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['is', 'financial', 'Report', 'of', 'The', 'share', 'of', 'large', 'borrowers', 'in', 'Indian', 'banks', 'total', 'loan', 'portfolios', 'stood', 'at', 'as', 'on', 'March', 'The', 'gross', 'assets', 'NPAs', 'as', 'a', 'percentage', 'of', 'total', 'loans', 'stood', 'at', 'as', 'on', 'March', 'Mumbai', 'Indian', 'banks', 'continue', 'to', 'see', 'an', 'improvement', 'in', 'asset', 'quality', 'with', 'bad', 'loans', 'as', 'a', 'percentage', 'of', 'total', 'loans', 'expected', 'to', 'fall', 'to', 'by', 'March', 'according', 'to', 'the', 'Financial', 'Stability', 'Report', 'released', 'by', 'the', 'Reserve', 'Bank', 'of', 'India', 'RBI', 'on', 'Thursday', 'The', 'gross', 'assets', 'NPAs', 'as', 'a', 'percentage', 'of', 'total', 'loans', 'stood', 'at', 'as', 'on', 'March', 'According', 'to', 'the', 'report', 'stress', 'tests', 'done', 'on']\n"
          ]
        }
      ],
      "source": [
        "print(words[:100])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "RGAtK-NLUKVT",
        "outputId": "1bd67cf9-e2e4-4158-caf0-8630f4678caf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wSfnfWInQNZP",
        "outputId": "b8a3548f-cf5f-418f-fc5b-e1e1ab65cfac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PHgHeVWfQNZQ"
      },
      "outputs": [],
      "source": [
        "words_token = [w for w in words if w not in stop_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YyBiz7V3QNZQ",
        "outputId": "20f73a61-7374-45e7-b8dd-cb038984f1fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['financial', 'Report', 'The', 'share', 'large', 'borrowers', 'Indian', 'banks', 'total', 'loan', 'portfolios', 'stood', 'March', 'The', 'gross', 'assets', 'NPAs', 'percentage', 'total', 'loans', 'stood', 'March', 'Mumbai', 'Indian', 'banks', 'continue', 'see', 'improvement', 'asset', 'quality', 'bad', 'loans', 'percentage', 'total', 'loans', 'expected', 'fall', 'March', 'according', 'Financial', 'Stability', 'Report', 'released', 'Reserve', 'Bank', 'India', 'RBI', 'Thursday', 'The', 'gross', 'assets', 'NPAs', 'percentage', 'total', 'loans', 'stood', 'March', 'According', 'report', 'stress', 'tests', 'done', 'public', 'sector', 'banks', 'PSBs', 'revealed', 'gross', 'ratio', 'may', 'decline', 'March', 'March', 'Private', 'sector', 'banks', 'could', 'see', 'fall', 'gross', 'NPAs', 'period', 'These', 'stress', 'tests', 'credit', 'risk', 'done', 'test', 'resilience', 'Indian', 'banks', 'macroeconomic', 'shocks', 'It', 'encompassed', 'baseline', 'two', 'medium', 'severe']\n"
          ]
        }
      ],
      "source": [
        "print(words_token[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vTFlnE_PQNZR",
        "outputId": "916e087d-4ce4-440e-9502-746239442c00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['financi', 'report', 'the', 'share', 'larg', 'borrow', 'indian', 'bank', 'total', 'loan', 'portfolio', 'stood', 'march', 'the', 'gross', 'asset', 'npa', 'percentag', 'total', 'loan', 'stood', 'march', 'mumbai', 'indian', 'bank', 'continu', 'see', 'improv', 'asset', 'qualiti', 'bad', 'loan', 'percentag', 'total', 'loan', 'expect', 'fall', 'march', 'accord', 'financi', 'stabil', 'report', 'releas', 'reserv', 'bank', 'india', 'rbi', 'thursday', 'the', 'gross', 'asset', 'npa', 'percentag', 'total', 'loan', 'stood', 'march', 'accord', 'report', 'stress', 'test', 'done', 'public', 'sector', 'bank', 'psb', 'reveal', 'gross', 'ratio', 'may', 'declin', 'march', 'march', 'privat', 'sector', 'bank', 'could', 'see', 'fall', 'gross', 'npa', 'period', 'these', 'stress', 'test', 'credit', 'risk', 'done', 'test', 'resili', 'indian', 'bank', 'macroeconom', 'shock', 'it', 'encompass', 'baselin', 'two', 'medium', 'sever']\n"
          ]
        }
      ],
      "source": [
        "# stemming of words\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "stemmed = [porter.stem(word) for word in words_token]\n",
        "print(stemmed[:100])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " nltk.download('udhr')"
      ],
      "metadata": {
        "id": "R3mO4ZR6a346",
        "outputId": "8496849a-eafe-429e-dcce-aaf2b0bbfc2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/udhr.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qjWDx5Z0QNZS",
        "outputId": "91fc8787-bbb7-4eb9-a8f4-ef48c3cce96b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Abkhaz-Cyrillic+Abkh',\n",
              " 'Abkhaz-UTF8',\n",
              " 'Achehnese-Latin1',\n",
              " 'Achuar-Shiwiar-Latin1',\n",
              " 'Adja-UTF8',\n",
              " 'Afaan_Oromo_Oromiffa-Latin1',\n",
              " 'Afrikaans-Latin1',\n",
              " 'Aguaruna-Latin1',\n",
              " 'Akuapem_Twi-UTF8',\n",
              " 'Albanian_Shqip-Latin1']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import udhr\n",
        "nltk.corpus.udhr.fileids()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('cess_esp')"
      ],
      "metadata": {
        "id": "NLe6WDS5a7Vy",
        "outputId": "117b6c7c-996e-43c7-fc4f-99a1ed7d5e0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cess_esp.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9HYeeGE0QNZS",
        "outputId": "bc44a795-f287-4e8f-eb9f-eb71cee1635e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['El',\n",
              " 'grupo',\n",
              " 'estatal',\n",
              " 'Electricité_de_France',\n",
              " '-Fpa-',\n",
              " 'EDF',\n",
              " '-Fpt-',\n",
              " 'anunció',\n",
              " 'hoy',\n",
              " ',']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "nltk.corpus.cess_esp.words()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Lp9BuYRQNZT"
      },
      "source": [
        "### Sentence tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ecnTy5t1QNZV"
      },
      "outputs": [],
      "source": [
        "EXAMPLE_TEXT = \"Hello Mr. Smith, how are you doing today? \\\n",
        "The weather is great, and Python is awsome !\\\n",
        "The sky is pinkish-blue. \\\n",
        "You shouldn't eat cardboard\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ltGbuGqzQNZW",
        "outputId": "ecbbc8a0-e8b3-44f8-a9d6-2b6b62a152f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello Mr. Smith, how are you doing today?',\n",
              " 'The weather is great, and Python is awsome !The sky is pinkish-blue.',\n",
              " \"You shouldn't eat cardboard\"]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "sent_tokenize(EXAMPLE_TEXT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gMn94alDQNZW",
        "outputId": "4b9c8504-1c6e-4f01-d239-498d1ab4dae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Mr. Smith, how are you doing today?\n",
            "The weather is great, and Python is awsome !The sky is pinkish-blue.\n",
            "You shouldn't eat cardboard\n"
          ]
        }
      ],
      "source": [
        "for sent in sent_tokenize(EXAMPLE_TEXT):\n",
        "    print(sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BthQR4mjQNZX"
      },
      "source": [
        "### word tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wX7YWcYHQNZX"
      },
      "outputs": [],
      "source": [
        "sentence = \"At eith o'clock on Thursday morning Arthur felt very good. Bue he didn't go to play\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "z-p-KS31QNZY",
        "outputId": "0a59e524-d696-4ca0-bd93-c5d25dda6c4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['At',\n",
              " 'eith',\n",
              " \"o'clock\",\n",
              " 'on',\n",
              " 'Thursday',\n",
              " 'morning',\n",
              " 'Arthur',\n",
              " 'felt',\n",
              " 'very',\n",
              " 'good',\n",
              " '.',\n",
              " 'Bue',\n",
              " 'he',\n",
              " 'did',\n",
              " \"n't\",\n",
              " 'go',\n",
              " 'to',\n",
              " 'play']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "word_tokenize(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eKnSvm_nQNZY",
        "outputId": "34a9073e-3dda-4096-85f5-f1c3c9898cb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'Mr.',\n",
              " 'Smith',\n",
              " ',',\n",
              " 'how',\n",
              " 'are',\n",
              " 'you',\n",
              " 'doing',\n",
              " 'today',\n",
              " '?',\n",
              " 'The',\n",
              " 'weather',\n",
              " 'is',\n",
              " 'great',\n",
              " ',',\n",
              " 'and',\n",
              " 'Python',\n",
              " 'is',\n",
              " 'awsome',\n",
              " '!',\n",
              " 'The',\n",
              " 'sky',\n",
              " 'is',\n",
              " 'pinkish-blue',\n",
              " '.',\n",
              " 'You',\n",
              " 'should',\n",
              " \"n't\",\n",
              " 'eat',\n",
              " 'cardboard']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "word_tokenize(EXAMPLE_TEXT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2F0zWYXNQNZY"
      },
      "outputs": [],
      "source": [
        "text = \"this is Ram's text , isn't it?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "q_nTal9jQNZY",
        "outputId": "51789aa6-f51d-4979-fca5-2ac74a79cbba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', \"Ram's\", 'text', ',', \"isn't\", 'it?']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "tokenizer.tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZzVlvC1TQNZZ",
        "outputId": "8ed53584-0559-41fd-8138-52954471801e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', 'Ram', \"'s\", 'text', ',', 'is', \"n't\", 'it', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
        "tokenizer.tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "35e3jh6LQNZZ",
        "outputId": "935eeaae-a4d7-481b-c492-d698411a148e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', 'Ram', \"'\", 's', 'text', ',', 'isn', \"'\", 't', 'it', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "tokenizer.tokenize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe2MkoR5QNZa"
      },
      "source": [
        "## stop Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5Xj0WbyRQNZa"
      },
      "outputs": [],
      "source": [
        "example_sent = \"This is a sample sentence, showing off the stop word filtration\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Bt7AILN4QNZa"
      },
      "outputs": [],
      "source": [
        "words_token = word_tokenize(example_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "y3OQwbFwQNZa",
        "outputId": "bb227de1-a4c1-49a7-a1ea-b188ec3cffc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'word', 'filtration']\n",
            "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'word', 'filtration']\n"
          ]
        }
      ],
      "source": [
        "# option1\n",
        "fitered_sent = [w for w in words_token if w not in stop_words]\n",
        "\n",
        "# option2\n",
        "fitered_sent = []\n",
        "for w in words_token:\n",
        "    if w not in stop_words:\n",
        "        fitered_sent.append(w)\n",
        "\n",
        "print(fitered_sent)\n",
        "print(words_token)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tcr-hRHEQNZb"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "pGyyWtTQQNZb"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "nmuxz3FjQNZb"
      },
      "outputs": [],
      "source": [
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "sno = SnowballStemmer('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "rXkSEtgWQNZb",
        "outputId": "151be296-85aa-482e-ab12-a810270a3d1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Lancaster Stemmer   Snoball Stemmer     \n",
            "connected           connect             connect             connect             \n",
            "connecting          connect             connect             connect             \n",
            "connecting          connect             connect             connect             \n",
            "connections         connect             connect             connect             \n"
          ]
        }
      ],
      "source": [
        "word_list = [\"connected\", \"connecting\", \"connecting\", \"connections\"]\n",
        "print(\"{0:20}{1:20}{2:20}{3:20}\".format(\"Word\", \"Porter Stemmer\", \"Lancaster Stemmer\", \"Snoball Stemmer\"))\n",
        "for word in word_list:\n",
        "    print(\"{0:20}{1:20}{2:20}{3:20}\".format(word, porter.stem(word), lancaster.stem(word), sno.stem(word)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjQY2OATQNZc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "SI6lOPgLQNZc"
      },
      "outputs": [],
      "source": [
        "word_list = [\"run\", \"running\", \"runs\", \"runner\", \"monthly\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_FjLbfiCQNZc",
        "outputId": "6cfcd142-4094-4cb3-9171-47e3906cb416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Lancaster Stemmer   Snoball Stemmer     \n",
            "run                 run                 run                 run                 \n",
            "running             run                 run                 run                 \n",
            "runs                run                 run                 run                 \n",
            "runner              runner              run                 runner              \n",
            "monthly             monthli             month               month               \n"
          ]
        }
      ],
      "source": [
        "print(\"{0:20}{1:20}{2:20}{3:20}\".format(\"Word\", \"Porter Stemmer\", \"Lancaster Stemmer\", \"Snoball Stemmer\"))\n",
        "for word in word_list:\n",
        "    print(\"{0:20}{1:20}{2:20}{3:20}\".format(word, porter.stem(word), lancaster.stem(word), sno.stem(word)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "lyj5Lvc8QNZc"
      },
      "outputs": [],
      "source": [
        "word_list = ['cats', \"trouble\", \"troubling\", \"troubled\", \"troublesome\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "fjlKbX16QNZd",
        "outputId": "c1549428-8a45-4abd-887f-13ae30816ce4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Lancaster Stemmer   Snoball Stemmer     \n",
            "cats                cat                 cat                 cat                 \n",
            "trouble             troubl              troubl              troubl              \n",
            "troubling           troubl              troubl              troubl              \n",
            "troubled            troubl              troubl              troubl              \n",
            "troublesome         troublesom          troublesom          troublesom          \n"
          ]
        }
      ],
      "source": [
        "print(\"{0:20}{1:20}{2:20}{3:20}\".format(\"Word\", \"Porter Stemmer\", \"Lancaster Stemmer\", \"Snoball Stemmer\"))\n",
        "for word in word_list:\n",
        "    print(\"{0:20}{1:20}{2:20}{3:20}\".format(word, porter.stem(word), lancaster.stem(word), sno.stem(word)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-eyrBwGQNZd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxFu3plnQNZd"
      },
      "source": [
        "### Lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kerQJO_NQNZp"
      },
      "source": [
        "The difference between stemming and lemmatization is : <br>\n",
        "    **Lemmatization considers the context and converts the word to its meaningful base form, where are stemming just removes the last few characters, of leading to incorrect meaning or spelling error**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tql1f0fyQNZq"
      },
      "source": [
        "- 'Caring'  -> Lemmatization -> 'Care'\n",
        "- 'Caring'  -> Stemming -> 'Car'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnXNDp1hQNZq"
      },
      "source": [
        "Ways to lemmatize:\n",
        "    \n",
        "    Wordnet Lemmatizer\n",
        "    Spacy Lemmatizer\n",
        "    TextBlob\n",
        "    CLiPS patter\n",
        "    Stanford CoreNLP\n",
        "    Gensim Lemmatizer\n",
        "    TreeTagger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "XCfqocSPQNZr"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "C9YKxMC9rW3x",
        "outputId": "c99ca27e-7119-42b0-c0f3-951d9ac2653c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "-4y2PbZNQNZr"
      },
      "outputs": [],
      "source": [
        "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\", \"stabilize\", \"destabilize\", \"misunderstanding\",\"railroad\", \"moonlight\",\"football\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "arpaSl_UQNZs",
        "outputId": "4441740b-598b-49d2-f028-2ab8d9456d05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                WordNetLemmatizer   porter              \n",
            "friend              friend              friend              \n",
            "friendship          friendship          friendship          \n",
            "friends             friend              friend              \n",
            "friendships         friendship          friendship          \n",
            "stabilize           stabilize           stabil              \n",
            "destabilize         destabilize         destabil            \n",
            "misunderstanding    misunderstanding    misunderstand       \n",
            "railroad            railroad            railroad            \n",
            "moonlight           moonlight           moonlight           \n",
            "football            football            footbal             \n"
          ]
        }
      ],
      "source": [
        "print(\"{0:20}{1:20}{2:20}\".format(\"Word\", \"WordNetLemmatizer\", \"porter\"))\n",
        "for word in word_list:\n",
        "    print(\"{0:20}{1:20}{2:20}\".format(word, lemmatizer.lemmatize(word), porter.stem(word)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHZwMgxeQNZs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}